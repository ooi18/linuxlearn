40 | 案例篇：网络请求延迟变大了，我该怎么办？
---

ddos 分布式,大流量,难追踪等特点,目前确实还没有办法,能够抵御 ddos 带来的影响.

比如我们可以购买专门的流量清洗设备和网络防火墙,在网络入口处阻断恶意流量，只保留正常流量进入数据中心的服务器。

除了 DDoS 会带来网络延迟增大外，我想，你肯定见到过不少其他原因导致的网络延迟，比如

- 网络传输慢，导致延迟；
- Linux 内核协议栈报文处理慢，导致延迟；
- 应用程序数据处理慢，导致延迟等等。


网络延迟
---

我相信，提到网络延迟时，你可能轻松想起它的含义——网络数据传输所用的时间。不过要注意，这个时间可能是单向的，指从源地址发送到目的地址的单程时间；也可能是双向的，即从源地址发送到目的地址，然后又从目的地址发回响应，这个往返全程所用的时间。

通常，我们更常用的是双向的往返通信延迟，比如 ping 测试的结果，就是往返延时 RTT（Round-Trip Time）。

除了网络延迟外，另一个常用的指标是应用程序延迟，它是指，从应用程序接收到请求，再到发回响应，全程所用的时间。通常，应用程序延迟也指的是往返延迟，是网络数据传输时间加上数据处理时间的和。

在 Linux 网络基础篇 中，我曾经介绍到，你可以用 ping 来测试网络延迟。ping 基于 ICMP 协议，它通过计算 ICMP 回显响应报文与 ICMP 回显请求报文的时间差，来获得往返延时。这个过程并不需要特殊认证，常被很多网络攻击利用，比如端口扫描工具 nmap、组包工具 hping3 等等。

所以，为了避免这些问题，很多网络服务会把 ICMP 禁止掉，这也就导致我们无法用 ping ，来测试网络服务的可用性和往返延时。这时，你可以用 traceroute 或 hping3 的 TCP 和 UDP 模式，来获取网络延迟。

比如，以 baidu.com 为例，你可以执行下面的 hping3 命令，测试你的机器到百度搜索服务器的网络延迟：


    # -c 表示发送 3 次请求，-S 表示设置 TCP SYN，-p 表示端口号为 80
    $ hping3 -c 3 -S -p 80 baidu.com
    HPING baidu.com (eth0 123.125.115.110): S set, 40 headers + 0 data bytes
    len=46 ip=123.125.115.110 ttl=51 id=47908 sport=80 flags=SA seq=0 win=8192 rtt=20.9 ms
    len=46 ip=123.125.115.110 ttl=51 id=6788  sport=80 flags=SA seq=1 win=8192 rtt=20.9 ms
    len=46 ip=123.125.115.110 ttl=51 id=37699 sport=80 flags=SA seq=2 win=8192 rtt=20.9 ms
    --- baidu.com hping statistic ---
    3 packets transmitted, 3 packets received, 0% packet loss
    round-trip min/avg/max = 20.9/20.9/20.9 ms

当然，我们用 traceroute ，也可以得到类似结果：

    # --tcp 表示使用 TCP 协议，-p 表示端口号，-n 表示不对结果中的 IP 地址执行反向域名解析
    $ traceroute --tcp -p 80 -n baidu.com
    traceroute to baidu.com (123.125.115.110), 30 hops max, 60 byte packets
    1  * * *
    2  * * *
    3  * * *
    4  * * *
    5  * * *
    6  * * *
    7  * * *
    8  * * *
    9  * * *
    10  * * *
    11  * * *
    12  * * *
    13  * * *
    14  123.125.115.110  20.684 ms *  20.798 ms

traceroute 会在路由的每一跳发送三个包，并在收到响应后，输出往返延时。如果无响应或者响应超时（默认 5s），就会输出一个星号。

案例
---


    docker run --network=host --name=good -itd nginx
    fb4ed7cb9177d10e270f8320a7fb64717eac3451114c9fab3c50e02be2e88ba2

继续在终端一中，执行下面的命令，运行案例应用，它会监听 8080 端口：

    docker run --name nginx --network=host -itd feisky/nginx:latency
    b99bd136dcfd907747d9c803fdc0255e578bad6d66f4e9c32b826d75b6812724

hping3 测试延迟

    # 测试 80 端口延迟
    $ hping3 -c 3 -S -p 80 192.168.0.30
    HPING 192.168.0.30 (eth0 192.168.0.30): S set, 40 headers + 0 data bytes
    len=44 ip=192.168.0.30 ttl=64 DF id=0 sport=80 flags=SA seq=0 win=29200 rtt=7.8 ms
    len=44 ip=192.168.0.30 ttl=64 DF id=0 sport=80 flags=SA seq=1 win=29200 rtt=7.7 ms
    len=44 ip=192.168.0.30 ttl=64 DF id=0 sport=80 flags=SA seq=2 win=29200 rtt=7.6 ms

    --- 192.168.0.30 hping statistic ---
    3 packets transmitted, 3 packets received, 0% packet loss
    round-trip min/avg/max = 7.6/7.7/7.8 ms



    # 测试 8080 端口延迟
    $ hping3 -c 3 -S -p 8080 192.168.0.30
    HPING 192.168.0.30 (eth0 192.168.0.30): S set, 40 headers + 0 data bytes
    len=44 ip=192.168.0.30 ttl=64 DF id=0 sport=8080 flags=SA seq=0 win=29200 rtt=7.7 ms
    len=44 ip=192.168.0.30 ttl=64 DF id=0 sport=8080 flags=SA seq=1 win=29200 rtt=7.6 ms
    len=44 ip=192.168.0.30 ttl=64 DF id=0 sport=8080 flags=SA seq=2 win=29200 rtt=7.3 ms

    --- 192.168.0.30 hping statistic ---
    3 packets transmitted, 3 packets received, 0% packet loss
    round-trip min/avg/max = 7.3/7.6/7.7 ms


从这个输出你可以看到，两个端口的延迟差不多，都是 7ms。不过，这只是单个请求的情况。换成并发请求的话，又会怎么样呢？接下来，我们就用 wrk 试试。


这次在终端二中，执行下面的新命令，分别测试案例机器并发 100 时， 80 端口和 8080 端口的性能：

    # 测试 80 端口性能
    $ # wrk --latency -c 100 -t 2 --timeout 2 http://192.168.0.30/
    Running 10s test @ http://192.168.0.30/
    2 threads and 100 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency     9.19ms   12.32ms 319.61ms   97.80%
        Req/Sec     6.20k   426.80     8.25k    85.50%
    Latency Distribution
        50%    7.78ms
        75%    8.22ms
        90%    9.14ms
        99%   50.53ms
    123558 requests in 10.01s, 100.15MB read
    Requests/sec:  12340.91
    Transfer/sec:     10.00MB


    # 测试 8080 端口性能
    $ wrk --latency -c 100 -t 2 --timeout 2 http://192.168.0.30:8080/
    Running 10s test @ http://192.168.0.30:8080/
    2 threads and 100 connections
    Thread Stats   Avg      Stdev     Max   +/- Stdev
        Latency    43.60ms    6.41ms  56.58ms   97.06%
        Req/Sec     1.15k   120.29     1.92k    88.50%
    Latency Distribution
        50%   44.02ms
        75%   44.33ms
        90%   47.62ms
        99%   48.88ms
    22853 requests in 10.01s, 18.55MB read
    Requests/sec:   2283.31
    Transfer/sec:      1.85MB

从上面两个输出可以看到，官方 Nginx（监听在 80 端口）的平均延迟是 9.19ms，而案例 Nginx 的平均延迟（监听在 8080 端口）则是 43.6ms。从延迟的分布上来看，官方 Nginx 90% 的请求，都可以在 9ms 以内完成；而案例 Nginx 50% 的请求，就已经达到了 44 ms。

再结合上面 hping3 的输出，我们很容易发现，案例 Nginx 在并发请求下的延迟增大了很多，这是怎么回事呢？

这里我们可以利用 tcpdump 抓包,并且保存到 pcap 文件当中,可以使用 wireshark 打开


    # 测试 8080 端口性能
    $ wrk --latency -c 100 -t 2 --timeout 2 http://192.168.0.30:8080/
    # 抓包
    tcpdump -nn tcp port 8080 -w nginx.pcap


参考
---

[40 | 案例篇：网络请求延迟变大了，我该怎么办？]https://time.geekbang.org/column/article/82833